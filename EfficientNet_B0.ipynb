{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run  dataset_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica si CUDA está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando el dispositivo: {device}\")\n",
    "\n",
    "# Cargar el modelo EfficientNet-B0 preentrenado\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Reemplazar la última capa para adaptarse a 2 clases (benigno y maligno)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "\n",
    "# Mover el modelo a la GPU si está disponible\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resumen del modelo\n",
    "input_size = (3, 224, 224)\n",
    "summary(model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9,weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para pérdidas y precisión\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Entrenamiento y evaluación\n",
    "epochs = 6\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # Entrenamiento\n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        # Mover datos a la GPU si está disponible\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass y optimización\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calcular precisión en el conjunto de entrenamiento\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluación en el conjunto de validación\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in vali_loader:\n",
    "\n",
    "            # Mover datos a la GPU si está disponible\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            running_val_loss += val_loss.item()\n",
    "            \n",
    "            # Calcular precisión en el conjunto de validación\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = running_val_loss / len(vali_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, \"\n",
    "          f\"Train Acc: {train_accuracy}, Val Acc: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar las pérdidas\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    # Usar el tamaño más pequeño entre train_losses y val_losses para los epochs\n",
    "    epochs = range(1, min(len(train_losses), len(val_losses)) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses[:len(epochs)], label='Training Loss')  # Asegurarse de que los tamaños coincidan\n",
    "    plt.plot(epochs, val_losses[:len(epochs)], label='Validation Loss')  # Cortar si hay más valores\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Efficienet')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Llamar a la función para graficar después del entrenamiento\n",
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, vali_loader):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in vali_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Obtener los logits del modelo\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Obtener la predicción más probable\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Contar las predicciones correctas\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    # Calcular y mostrar la precisión\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    print(f'Accuracy on test set: {accuracy:.4f}')\n",
    "\n",
    "# Llama a la función de prueba del modelo\n",
    "test_model(model, vali_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el estado del modelo\n",
    "torch.save(model, 'Efficienet_B0 .pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo guardado (modifica la ruta según corresponda)\n",
    "model = torch.load('D://TrabajoGrado//CodiDatos//archive//Efficienet_B0 .pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Etiquetas verdaderas y predicciones del modelo\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Desactivar gradientes para el cálculo (modo evaluación)\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:  \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Obtener predicciones\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Guardar las etiquetas reales y predichas\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "matriz_confusion = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Graficar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matriz_confusion, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicciones')\n",
    "plt.ylabel('Etiquetas Verdaderas')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de las etiquetas\n",
    "class_names = ['Benigno', 'Maligno']\n",
    "\n",
    "# Generar la matriz de confusión \n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Configurar el gráfico\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "# Etiquetas y título\n",
    "plt.xlabel('Predicciones')\n",
    "plt.ylabel('Etiquetas Verdaderas')\n",
    "plt.title('Matriz de Confusión Efficienet-B0')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
